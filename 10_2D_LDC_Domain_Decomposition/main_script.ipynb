{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d787cdb7",
   "metadata": {},
   "source": [
    "## 问题定义\n",
    "\n",
    "问题定义如下图，矩形求解区域，长宽为0.1m，上侧面为从左至右的1m/s的滑移边界，其他三个侧面为无滑移边界。雷诺数为10。\n",
    "![Problem](./resource/problem_define.png)\n",
    "\n",
    "对待求解问题的数学描述如下：\n",
    "![Equation](./resource/equation.png)\n",
    "\n",
    "其中，$u,v$分别为x方向速度，y方向速度，$p$为压强，$\\nu,\\rho$分别为运动粘度和密度。在本求解中定义$\\nu=0.01$，$\\rho=1.0$\n",
    "\n",
    "### 求解目标\n",
    "\n",
    "给定坐标$(x,y)$求解稳态结果（$u,v, p$）\n",
    "\n",
    "## Domain Decomposition\n",
    "\n",
    "本例的目的是引入域分解方法\n",
    "\n",
    "整个求解域被分解为两部分，两部分单独求解\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b4e6a5",
   "metadata": {},
   "source": [
    "## 求解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1f223f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "# optional\n",
    "# set appropriate GPU in case of multi-GPU machine\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd0cf1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 必要的符号运算\n",
    "from sympy import Symbol, Eq, Abs, Heaviside\n",
    "\n",
    "import modulus.sym\n",
    "\n",
    "# 超参数\n",
    "from modulus.sym.hydra import to_yaml\n",
    "from modulus.sym.hydra import to_absolute_path, instantiate_arch, ModulusConfig\n",
    "from modulus.sym.hydra.utils import compose\n",
    "\n",
    "# 求解器\n",
    "from modulus.sym.solver import Solver\n",
    "\n",
    "# domain\n",
    "from modulus.sym.domain import Domain\n",
    "\n",
    "# 几何物体\n",
    "from modulus.sym.geometry.primitives_2d import Rectangle\n",
    "\n",
    "# 约束\n",
    "from modulus.sym.domain.constraint import (\n",
    "    PointwiseBoundaryConstraint,\n",
    "    PointwiseInteriorConstraint,\n",
    ")\n",
    "\n",
    "# validator\n",
    "from modulus.sym.domain.validator import PointwiseValidator\n",
    "\n",
    "# inferencer\n",
    "from modulus.sym.domain.inferencer import PointwiseInferencer\n",
    "from modulus.sym.key import Key\n",
    "\n",
    "# Equation\n",
    "from modulus.sym.eq.pdes.navier_stokes import NavierStokes\n",
    "\n",
    "# post process\n",
    "from modulus.sym.utils.io import (\n",
    "    csv_to_dict,\n",
    "    ValidatorPlotter,\n",
    "    InferencerPlotter,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from modulus.sym.node import Node\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "613f5d80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/modulus/sym/hydra/utils.py:148: UserWarning: \n",
      "The version_base parameter is not specified.\n",
      "Please specify a compatability version level, or None.\n",
      "Will assume defaults for version 1.1\n",
      "  hydra.initialize(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training:\n",
      "  max_steps: 10000\n",
      "  grad_agg_freq: 1\n",
      "  rec_results_freq: 1000\n",
      "  rec_validation_freq: 1000\n",
      "  rec_inference_freq: 2000\n",
      "  rec_monitor_freq: 1000\n",
      "  rec_constraint_freq: 2000\n",
      "  save_network_freq: 1000\n",
      "  print_stats_freq: 100\n",
      "  summary_freq: 1000\n",
      "  amp: false\n",
      "  amp_dtype: float16\n",
      "  ntk:\n",
      "    use_ntk: false\n",
      "    save_name: null\n",
      "    run_freq: 1000\n",
      "graph:\n",
      "  func_arch: true\n",
      "  func_arch_allow_partial_hessian: true\n",
      "stop_criterion:\n",
      "  metric: null\n",
      "  min_delta: null\n",
      "  patience: 50000\n",
      "  mode: min\n",
      "  freq: 1000\n",
      "  strict: false\n",
      "profiler:\n",
      "  profile: false\n",
      "  start_step: 0\n",
      "  end_step: 100\n",
      "  name: nvtx\n",
      "network_dir: outputs\n",
      "initialization_network_dir: ''\n",
      "save_filetypes: vtk,npz\n",
      "summary_histograms: false\n",
      "jit: true\n",
      "jit_use_nvfuser: true\n",
      "jit_arch_mode: only_activation\n",
      "jit_autograd_nodes: false\n",
      "cuda_graphs: true\n",
      "cuda_graph_warmup: 20\n",
      "find_unused_parameters: false\n",
      "broadcast_buffers: false\n",
      "device: ''\n",
      "debug: false\n",
      "run_mode: train\n",
      "arch:\n",
      "  fully_connected:\n",
      "    arch_type: fully_connected\n",
      "    input_keys: ???\n",
      "    output_keys: ???\n",
      "    detach_keys: ???\n",
      "    scaling: null\n",
      "    layer_size: 512\n",
      "    nr_layers: 6\n",
      "    skip_connections: false\n",
      "    activation_fn: silu\n",
      "    adaptive_activations: false\n",
      "    weight_norm: true\n",
      "models: ???\n",
      "loss:\n",
      "  _target_: modulus.sym.loss.aggregator.Sum\n",
      "  weights: null\n",
      "optimizer:\n",
      "  _params_:\n",
      "    compute_gradients: adam_compute_gradients\n",
      "    apply_gradients: adam_apply_gradients\n",
      "  _target_: torch.optim.Adam\n",
      "  lr: 0.001\n",
      "  betas:\n",
      "  - 0.9\n",
      "  - 0.999\n",
      "  eps: 1.0e-08\n",
      "  weight_decay: 0.0\n",
      "  amsgrad: false\n",
      "scheduler:\n",
      "  _target_: custom\n",
      "  _name_: tf.ExponentialLR\n",
      "  decay_rate: 0.95\n",
      "  decay_steps: 4000\n",
      "batch_size:\n",
      "  TopWall: 1000\n",
      "  NoSlip: 1000\n",
      "  Interior: 4000\n",
      "custom: ???\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cfg = compose(config_path=\"conf\", config_name=\"config\")\n",
    "cfg.network_dir = 'outputs'    # Set the network directory for checkpoints\n",
    "print(to_yaml(cfg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d70fc0",
   "metadata": {},
   "source": [
    "### 定义必要组件"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e575f4c2",
   "metadata": {},
   "source": [
    "#### PDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3ab702f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'continuity_1': 1.0*Derivative(u_1(x, y), x) + 1.0*Derivative(v_1(x, y), y), 'momentum_x_1': 1.0*u_1(x, y)*Derivative(u_1(x, y), x) + 1.0*v_1(x, y)*Derivative(u_1(x, y), y) + Derivative(p_1(x, y), x) - 0.01*Derivative(u_1(x, y), (x, 2)) - 0.01*Derivative(u_1(x, y), (y, 2)), 'momentum_y_1': 1.0*u_1(x, y)*Derivative(v_1(x, y), x) + 1.0*v_1(x, y)*Derivative(v_1(x, y), y) + Derivative(p_1(x, y), y) - 0.01*Derivative(v_1(x, y), (x, 2)) - 0.01*Derivative(v_1(x, y), (y, 2))}\n",
      "{'continuity_2': 1.0*Derivative(u_2(x, y), x) + 1.0*Derivative(v_2(x, y), y), 'momentum_x_2': 1.0*u_2(x, y)*Derivative(u_2(x, y), x) + 1.0*v_2(x, y)*Derivative(u_2(x, y), y) + Derivative(p_2(x, y), x) - 0.01*Derivative(u_2(x, y), (x, 2)) - 0.01*Derivative(u_2(x, y), (y, 2)), 'momentum_y_2': 1.0*u_2(x, y)*Derivative(v_2(x, y), x) + 1.0*v_2(x, y)*Derivative(v_2(x, y), y) + Derivative(p_2(x, y), y) - 0.01*Derivative(v_2(x, y), (x, 2)) - 0.01*Derivative(v_2(x, y), (y, 2))}\n"
     ]
    }
   ],
   "source": [
    "ns = NavierStokes(nu=0.01, rho=1.0, dim=2, time=False)\n",
    "\n",
    "# 每一个域均需要有独立的NS方程\n",
    "def generate_pde_copies(eq, num_copies=2):  # deep copy所有方程以及变量\n",
    "    \"\"\"\n",
    "    Generate multiple copies of a equation to use it\n",
    "    for different domains.\n",
    "    \"\"\"\n",
    "\n",
    "    from sympy import Function\n",
    "\n",
    "    eq_copies = []\n",
    "    for i in range(num_copies):\n",
    "        temp_eq = copy.deepcopy(eq)\n",
    "\n",
    "        # Find all the functions that need substituion\n",
    "        eq_sum = 0\n",
    "        for k, v in temp_eq.equations.items():\n",
    "            eq_sum += v  # Generate a single equation to find all the terms.\n",
    "\n",
    "        for func in eq_sum.atoms(Function):\n",
    "            func_new_str = func.func.__name__ + \"_\" + str(i + 1)\n",
    "            args = func.args\n",
    "            func_new = Function(func_new_str)(*args)\n",
    "            temp_eq.subs(func, func_new)\n",
    "\n",
    "        # Generate the functions to be substituted\n",
    "        equations_new = {}\n",
    "        for k, v in temp_eq.equations.items():\n",
    "            equations_new[k + \"_\" + str(i + 1)] = v\n",
    "\n",
    "        # Replace the equations dict\n",
    "        temp_eq.equations = equations_new\n",
    "        eq_copies.append(temp_eq)\n",
    "\n",
    "    return eq_copies\n",
    "\n",
    "copies = generate_pde_copies(ns, num_copies=2)\n",
    "for eq in copies:\n",
    "    print(eq.equations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee27a28",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a3af9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FullyConnectedArch(\n",
      "  (_impl): FullyConnectedArchCore(\n",
      "    (layers): ModuleList(\n",
      "      (0): FCLayer(\n",
      "        (linear): WeightNormLinear(in_features=2, out_features=512, bias=True)\n",
      "      )\n",
      "      (1-5): 5 x FCLayer(\n",
      "        (linear): WeightNormLinear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (final_layer): FCLayer(\n",
      "      (activation_fn): Identity()\n",
      "      (linear): Linear(in_features=512, out_features=3, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 定义简单的全连接网络\n",
    "# 输入为坐标x和y\n",
    "# 输出为两个方向的速度u,v以及压强p\n",
    "\n",
    "# 两个域需要两个模型\n",
    "flow_net_1 = instantiate_arch(\n",
    "    input_keys=[Key(\"x\"), Key(\"y\")],\n",
    "    output_keys=[Key(\"u_1\"), Key(\"v_1\"), Key(\"p_1\")],\n",
    "    cfg=cfg.arch.fully_connected,\n",
    ")\n",
    "flow_net_2 = instantiate_arch(\n",
    "    input_keys=[Key(\"x\"), Key(\"y\")],\n",
    "    output_keys=[Key(\"u_2\"), Key(\"v_2\"), Key(\"p_2\")],\n",
    "    cfg=cfg.arch.fully_connected,\n",
    ")\n",
    "\n",
    "print(flow_net_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab6f1a5",
   "metadata": {},
   "source": [
    "#### Interface Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d221355a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 两个区域的界面损失\n",
    "interface_nodes = [Node.from_sympy(Symbol(\"u_1\") - Symbol(\"u_2\"), \"dirichlet_u\")]\n",
    "interface_nodes += [Node.from_sympy(Symbol(\"v_1\") - Symbol(\"v_2\"), \"dirichlet_v\")]\n",
    "interface_nodes += [Node.from_sympy(Symbol(\"p_1\") - Symbol(\"p_2\"), \"dirichlet_p\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b724aeb",
   "metadata": {},
   "source": [
    "#### 推理节点\n",
    "\n",
    "最终的解是两个独立模型的组合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37947723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heaviside： 阶跃函数\n",
    "custom_nodes = [\n",
    "    Node.from_sympy(\n",
    "        Symbol(\"u_1\") * Heaviside(-Symbol(\"y\"))\n",
    "        + Symbol(\"u_2\") * Heaviside(Symbol(\"y\")),\n",
    "        \"u\",\n",
    "    )\n",
    "]\n",
    "custom_nodes += [\n",
    "    Node.from_sympy(\n",
    "        Symbol(\"v_1\") * Heaviside(-Symbol(\"y\"))\n",
    "        + Symbol(\"v_2\") * Heaviside(Symbol(\"y\")),\n",
    "        \"v\",\n",
    "    )\n",
    "]\n",
    "custom_nodes += [\n",
    "    Node.from_sympy(\n",
    "        Symbol(\"p_1\") * Heaviside(-Symbol(\"y\"))\n",
    "        + Symbol(\"p_2\") * Heaviside(Symbol(\"y\")),\n",
    "        \"p\",\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736b4e07",
   "metadata": {},
   "source": [
    "#### 整合节点\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "caa66dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = (\n",
    "    copies[0].make_nodes()  # 方程0的计算图\n",
    "    + copies[1].make_nodes()  # 方程1的计算图\n",
    "    + interface_nodes  # 界面损失节点\n",
    "    + [flow_net_1.make_node(name=\"flow_network_1\")]  # 模型节点1\n",
    "    + [flow_net_2.make_node(name=\"flow_network_2\")]  # 模型节点2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89dd25e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 推理节点图\n",
    "nodes_infer = custom_nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04c5f83",
   "metadata": {},
   "source": [
    "#### Geo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65384d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 长宽均为1的矩形\n",
    "height = 0.1\n",
    "width = 0.1\n",
    "x, y = Symbol(\"x\"), Symbol(\"y\")\n",
    "\n",
    "# 定义两个子区域\n",
    "rec_1 = Rectangle((-width / 2, -height / 2), (width / 2, 0))\n",
    "rec_2 = Rectangle((-width / 2, 0), (width / 2, height / 2))\n",
    "\n",
    "# 整个区域\n",
    "rec = Rectangle((-width / 2, -height / 2), (width / 2, height / 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52efd6c",
   "metadata": {},
   "source": [
    "#### Domain\n",
    "\n",
    "在Domain中定义约束以及训练所需的各种组件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c7f0404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make ldc domain\n",
    "ldc_domain = Domain()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b59687",
   "metadata": {},
   "source": [
    "#### 边界条件\n",
    "\n",
    "四个边界条件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2dc4b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 顶部滑移边界\n",
    "# 水平速度为1.0，垂直速度为0\n",
    "# 注意lambda_weighting参数，这个参数定义了样本权重，在本示例中，约靠近边界，样本的权重越小\n",
    "# criteria定义了采样的位置\n",
    "# outvar定义了边界条件\n",
    "\n",
    "# 上边界全部在模型2的范围内\n",
    "top_wall = PointwiseBoundaryConstraint(\n",
    "    nodes=nodes,\n",
    "    geometry=rec_2,\n",
    "    outvar={\"u_2\": 1.0, \"v_2\": 0},\n",
    "    batch_size=cfg.batch_size.TopWall,\n",
    "    lambda_weighting={\n",
    "        \"u_2\": 1.0 - 20 * Abs(x),\n",
    "        \"v_2\": 1.0,\n",
    "    },  # weight edges to be zero\n",
    "    criteria=Eq(y, height / 2),\n",
    ")\n",
    "ldc_domain.add_constraint(top_wall, \"top_wall\")\n",
    "\n",
    "\n",
    "# 左右以及下侧的无滑移边界\n",
    "# 这里简化了写法\n",
    "# 实际上两个模型在三个边界上均有监督\n",
    "no_slip = PointwiseBoundaryConstraint(\n",
    "    nodes=nodes,\n",
    "    geometry=rec,\n",
    "    outvar={\"u_1\": 0, \"v_1\": 0, \"u_2\": 0, \"v_2\": 0},\n",
    "    batch_size=cfg.batch_size.NoSlip,\n",
    "    criteria=y < height / 2,\n",
    ")\n",
    "ldc_domain.add_constraint(no_slip, \"no_slip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687c086c",
   "metadata": {},
   "source": [
    "#### PDE约束\n",
    "\n",
    "内部满足PDE约束"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11798bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interior\n",
    "# 由于本求解中NS方程直接调用的模型，所以这里outvar直接使用了对应的key\n",
    "# 具体定义可参考modulus/eq/pdes/navier_stokes.py\n",
    "interior = PointwiseInteriorConstraint(\n",
    "    nodes=nodes,\n",
    "    geometry=rec,\n",
    "    outvar={\"continuity_2\": 0, \"momentum_x_2\": 0, \"momentum_y_2\": 0},\n",
    "    batch_size=cfg.batch_size.Interior // 2,\n",
    "    lambda_weighting={\n",
    "        \"continuity_2\": Symbol(\"sdf\"),\n",
    "        \"momentum_x_2\": Symbol(\"sdf\"),\n",
    "        \"momentum_y_2\": Symbol(\"sdf\"),\n",
    "    },\n",
    "    criteria=y > 0,  # 通过条件指定范围\n",
    ")\n",
    "ldc_domain.add_constraint(interior, \"interior_2\")\n",
    "\n",
    "interior = PointwiseInteriorConstraint(\n",
    "    nodes=nodes,\n",
    "    geometry=rec,\n",
    "    outvar={\"continuity_1\": 0, \"momentum_x_1\": 0, \"momentum_y_1\": 0},\n",
    "    batch_size=cfg.batch_size.Interior // 2,\n",
    "    lambda_weighting={\n",
    "        \"continuity_1\": Symbol(\"sdf\"),\n",
    "        \"momentum_x_1\": Symbol(\"sdf\"),\n",
    "        \"momentum_y_1\": Symbol(\"sdf\"),\n",
    "    },\n",
    "    criteria=y < 0,  # 通过条件指定范围\n",
    ")\n",
    "ldc_domain.add_constraint(interior, \"interior_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12c6562",
   "metadata": {},
   "source": [
    "#### 界面约束"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99ed71d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interface\n",
    "interface = PointwiseBoundaryConstraint(\n",
    "    nodes=nodes,\n",
    "    geometry=rec_1,\n",
    "    outvar={\"dirichlet_u\": 0, \"dirichlet_v\": 0, \"dirichlet_p\": 0},\n",
    "    batch_size=cfg.batch_size.NoSlip,\n",
    "    criteria=Eq(y, 0),\n",
    ")\n",
    "ldc_domain.add_constraint(interface, \"interface\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c0e57c",
   "metadata": {},
   "source": [
    "验证器以及其他必要组件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a81d5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据目录\n",
    "file_path = \"openfoam/cavity_uniformVel0.csv\"\n",
    "if os.path.exists(to_absolute_path(file_path)):\n",
    "    mapping = {\"Points:0\": \"x\", \"Points:1\": \"y\", \"U:0\": \"u\", \"U:1\": \"v\", \"p\": \"p\"}\n",
    "    openfoam_var = csv_to_dict(to_absolute_path(file_path), mapping)\n",
    "    openfoam_var[\"x\"] += -width / 2  # center OpenFoam data\n",
    "    openfoam_var[\"y\"] += -height / 2  # center OpenFoam data\n",
    "    \n",
    "    # 输入数据\n",
    "    openfoam_invar_numpy = {\n",
    "        key: value for key, value in openfoam_var.items() if key in [\"x\", \"y\"]\n",
    "    }\n",
    "    # 输出数据\n",
    "    openfoam_outvar_numpy = {\n",
    "        key: value for key, value in openfoam_var.items() if key in [\"u\", \"v\"]\n",
    "    }\n",
    "    \n",
    "    # 创建validator\n",
    "    openfoam_validator = PointwiseValidator(\n",
    "        nodes=nodes + nodes_infer,  # 注意这个位置，推理使用率nodes_infer\n",
    "        invar=openfoam_invar_numpy,\n",
    "        true_outvar=openfoam_outvar_numpy,\n",
    "        batch_size=1024,\n",
    "        plotter=ValidatorPlotter(),\n",
    "    )\n",
    "    ldc_domain.add_validator(openfoam_validator)\n",
    "\n",
    "    # 创建inferencer\n",
    "    # 独立的\n",
    "    samples = rec_1.sample_interior(10000)\n",
    "    # add inferencer data\n",
    "    grid_inference = PointwiseInferencer(\n",
    "        nodes=nodes,\n",
    "        invar={\"x\": samples[\"x\"], \"y\": samples[\"y\"]},\n",
    "        output_names=[\"u_1\", \"v_1\", \"p_1\"],\n",
    "        batch_size=1024,\n",
    "        plotter=InferencerPlotter(),\n",
    "    )\n",
    "    ldc_domain.add_inferencer(grid_inference, \"inf_data_1\")\n",
    "\n",
    "    samples = rec_2.sample_interior(10000)\n",
    "    # add inferencer data\n",
    "    grid_inference = PointwiseInferencer(\n",
    "        nodes=nodes,\n",
    "        invar={\"x\": samples[\"x\"], \"y\": samples[\"y\"]},\n",
    "        output_names=[\"u_2\", \"v_2\", \"p_2\"],\n",
    "        batch_size=1024,\n",
    "        plotter=InferencerPlotter(),\n",
    "    )\n",
    "    ldc_domain.add_inferencer(grid_inference, \"inf_data_2\")\n",
    "else:\n",
    "    warnings.warn(\n",
    "        f\"Directory {file_path} does not exist. Will skip adding validators. Please download the additional files from NGC https://catalog.ngc.nvidia.com/orgs/nvidia/teams/modulus/resources/modulus_sym_examples_supplemental_materials\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473c37fb",
   "metadata": {},
   "source": [
    "### 求解器以及求解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97b90486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义求解器\n",
    "slv = Solver(cfg, ldc_domain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9af551",
   "metadata": {},
   "source": [
    "手动加载日志系统"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39932aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "# logging.getLogger().addHandler(logging.StreamHandler())\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# create console handler and set level to debug\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.INFO)\n",
    "\n",
    "# create formatter\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# add formatter to ch\n",
    "ch.setFormatter(formatter)\n",
    "\n",
    "# add ch to logger\n",
    "logger.addHandler(ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8adfbd",
   "metadata": {},
   "source": [
    "启动求解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9b2fdb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 09:14:08,066 - modulus.sym.trainer - WARNING - Installed PyTorch version 2.2.0a0+81ea7a4 is not TorchScript supported in Modulus. Version 2.1.0a0+4136153 is officially supported.\n",
      "2024-02-27 09:14:08,076 - modulus.sym.trainer - INFO - attempting to restore from: /workspace/10_2D_LDC_Domain_Decomposition/outputs\n",
      "2024-02-27 09:14:08,077 - modulus.sym.trainer - WARNING - optimizer checkpoint not found\n",
      "2024-02-27 09:14:08,079 - modulus.sym.trainer - WARNING - model flow_network_1.0.pth not found\n",
      "2024-02-27 09:14:08,080 - modulus.sym.trainer - WARNING - model flow_network_2.0.pth not found\n",
      "2024-02-27 09:14:09,806 - modulus.sym.trainer - INFO - [step:          0] record constraint batch time:  1.065e-01s\n",
      "2024-02-27 09:14:16,596 - modulus.sym.trainer - INFO - [step:          0] record validators time:  6.788e+00s\n",
      "2024-02-27 09:14:18,668 - modulus.sym.trainer - INFO - [step:          0] record inferencers time:  2.050e+00s\n",
      "2024-02-27 09:14:18,731 - modulus.sym.trainer - INFO - [step:          0] saved checkpoint to /workspace/10_2D_LDC_Domain_Decomposition/outputs\n",
      "2024-02-27 09:14:18,733 - modulus.sym.trainer - INFO - [step:          0] loss:  4.993e-02\n",
      "2024-02-27 09:14:21,626 - modulus.sym.trainer - INFO - Attempting cuda graph building, this may take a bit...\n",
      "2024-02-27 09:14:35,375 - modulus.sym.trainer - INFO - [step:        100] loss:  8.294e-03, time/iteration:  1.664e+02 ms\n",
      "2024-02-27 09:14:39,129 - modulus.sym.trainer - INFO - [step:        200] loss:  5.270e-03, time/iteration:  3.749e+01 ms\n",
      "2024-02-27 09:14:42,926 - modulus.sym.trainer - INFO - [step:        300] loss:  4.648e-03, time/iteration:  3.794e+01 ms\n",
      "2024-02-27 09:14:46,722 - modulus.sym.trainer - INFO - [step:        400] loss:  3.612e-03, time/iteration:  3.793e+01 ms\n",
      "2024-02-27 09:14:50,494 - modulus.sym.trainer - INFO - [step:        500] loss:  2.856e-03, time/iteration:  3.767e+01 ms\n",
      "2024-02-27 09:14:54,263 - modulus.sym.trainer - INFO - [step:        600] loss:  2.898e-03, time/iteration:  3.765e+01 ms\n",
      "2024-02-27 09:14:58,034 - modulus.sym.trainer - INFO - [step:        700] loss:  2.524e-03, time/iteration:  3.768e+01 ms\n",
      "2024-02-27 09:15:01,804 - modulus.sym.trainer - INFO - [step:        800] loss:  2.491e-03, time/iteration:  3.765e+01 ms\n",
      "2024-02-27 09:15:05,537 - modulus.sym.trainer - INFO - [step:        900] loss:  2.398e-03, time/iteration:  3.729e+01 ms\n",
      "2024-02-27 09:15:17,161 - modulus.sym.trainer - INFO - [step:       1000] record validators time:  6.960e+00s\n",
      "2024-02-27 09:15:17,258 - modulus.sym.trainer - INFO - [step:       1000] saved checkpoint to /workspace/10_2D_LDC_Domain_Decomposition/outputs\n",
      "2024-02-27 09:15:17,260 - modulus.sym.trainer - INFO - [step:       1000] loss:  1.949e-03, time/iteration:  1.172e+02 ms\n",
      "2024-02-27 09:15:20,994 - modulus.sym.trainer - INFO - [step:       1100] loss:  1.602e-03, time/iteration:  3.733e+01 ms\n",
      "2024-02-27 09:15:24,768 - modulus.sym.trainer - INFO - [step:       1200] loss:  1.512e-03, time/iteration:  3.770e+01 ms\n",
      "2024-02-27 09:15:28,496 - modulus.sym.trainer - INFO - [step:       1300] loss:  1.027e-03, time/iteration:  3.726e+01 ms\n",
      "2024-02-27 09:15:32,262 - modulus.sym.trainer - INFO - [step:       1400] loss:  1.104e-03, time/iteration:  3.764e+01 ms\n",
      "2024-02-27 09:15:35,991 - modulus.sym.trainer - INFO - [step:       1500] loss:  1.019e-03, time/iteration:  3.724e+01 ms\n",
      "2024-02-27 09:15:39,718 - modulus.sym.trainer - INFO - [step:       1600] loss:  1.205e-03, time/iteration:  3.725e+01 ms\n",
      "2024-02-27 09:15:43,489 - modulus.sym.trainer - INFO - [step:       1700] loss:  8.353e-04, time/iteration:  3.769e+01 ms\n",
      "2024-02-27 09:15:47,217 - modulus.sym.trainer - INFO - [step:       1800] loss:  8.915e-04, time/iteration:  3.724e+01 ms\n",
      "2024-02-27 09:15:50,943 - modulus.sym.trainer - INFO - [step:       1900] loss:  7.657e-04, time/iteration:  3.723e+01 ms\n",
      "2024-02-27 09:15:55,692 - modulus.sym.trainer - INFO - [step:       2000] record constraint batch time:  1.177e-01s\n",
      "2024-02-27 09:16:02,467 - modulus.sym.trainer - INFO - [step:       2000] record validators time:  6.771e+00s\n",
      "2024-02-27 09:16:04,572 - modulus.sym.trainer - INFO - [step:       2000] record inferencers time:  2.087e+00s\n",
      "2024-02-27 09:16:04,645 - modulus.sym.trainer - INFO - [step:       2000] saved checkpoint to /workspace/10_2D_LDC_Domain_Decomposition/outputs\n",
      "2024-02-27 09:16:04,647 - modulus.sym.trainer - INFO - [step:       2000] loss:  6.398e-04, time/iteration:  1.370e+02 ms\n",
      "2024-02-27 09:16:08,387 - modulus.sym.trainer - INFO - [step:       2100] loss:  6.251e-04, time/iteration:  3.739e+01 ms\n",
      "2024-02-27 09:16:12,109 - modulus.sym.trainer - INFO - [step:       2200] loss:  5.969e-04, time/iteration:  3.720e+01 ms\n",
      "2024-02-27 09:16:15,829 - modulus.sym.trainer - INFO - [step:       2300] loss:  5.342e-04, time/iteration:  3.718e+01 ms\n",
      "2024-02-27 09:16:19,552 - modulus.sym.trainer - INFO - [step:       2400] loss:  7.061e-04, time/iteration:  3.722e+01 ms\n",
      "2024-02-27 09:16:23,314 - modulus.sym.trainer - INFO - [step:       2500] loss:  5.131e-04, time/iteration:  3.758e+01 ms\n",
      "2024-02-27 09:16:27,035 - modulus.sym.trainer - INFO - [step:       2600] loss:  4.568e-04, time/iteration:  3.719e+01 ms\n",
      "2024-02-27 09:16:30,759 - modulus.sym.trainer - INFO - [step:       2700] loss:  7.301e-04, time/iteration:  3.722e+01 ms\n",
      "2024-02-27 09:16:34,479 - modulus.sym.trainer - INFO - [step:       2800] loss:  7.830e-04, time/iteration:  3.718e+01 ms\n",
      "2024-02-27 09:16:38,207 - modulus.sym.trainer - INFO - [step:       2900] loss:  5.233e-04, time/iteration:  3.727e+01 ms\n",
      "2024-02-27 09:16:49,565 - modulus.sym.trainer - INFO - [step:       3000] record validators time:  6.735e+00s\n",
      "2024-02-27 09:16:49,656 - modulus.sym.trainer - INFO - [step:       3000] saved checkpoint to /workspace/10_2D_LDC_Domain_Decomposition/outputs\n",
      "2024-02-27 09:16:49,657 - modulus.sym.trainer - INFO - [step:       3000] loss:  3.745e-04, time/iteration:  1.145e+02 ms\n",
      "2024-02-27 09:16:53,390 - modulus.sym.trainer - INFO - [step:       3100] loss:  3.734e-04, time/iteration:  3.732e+01 ms\n",
      "2024-02-27 09:16:57,116 - modulus.sym.trainer - INFO - [step:       3200] loss:  3.550e-04, time/iteration:  3.724e+01 ms\n",
      "2024-02-27 09:17:00,839 - modulus.sym.trainer - INFO - [step:       3300] loss:  6.080e-04, time/iteration:  3.722e+01 ms\n",
      "2024-02-27 09:17:04,562 - modulus.sym.trainer - INFO - [step:       3400] loss:  4.563e-04, time/iteration:  3.721e+01 ms\n",
      "2024-02-27 09:17:08,284 - modulus.sym.trainer - INFO - [step:       3500] loss:  6.968e-04, time/iteration:  3.721e+01 ms\n",
      "2024-02-27 09:17:12,006 - modulus.sym.trainer - INFO - [step:       3600] loss:  3.909e-04, time/iteration:  3.720e+01 ms\n",
      "2024-02-27 09:17:15,737 - modulus.sym.trainer - INFO - [step:       3700] loss:  2.845e-04, time/iteration:  3.729e+01 ms\n",
      "2024-02-27 09:17:19,494 - modulus.sym.trainer - INFO - [step:       3800] loss:  3.483e-04, time/iteration:  3.753e+01 ms\n",
      "2024-02-27 09:17:23,222 - modulus.sym.trainer - INFO - [step:       3900] loss:  5.985e-04, time/iteration:  3.726e+01 ms\n",
      "2024-02-27 09:17:27,927 - modulus.sym.trainer - INFO - [step:       4000] record constraint batch time:  1.155e-01s\n",
      "2024-02-27 09:17:35,031 - modulus.sym.trainer - INFO - [step:       4000] record validators time:  7.103e+00s\n",
      "2024-02-27 09:17:37,098 - modulus.sym.trainer - INFO - [step:       4000] record inferencers time:  2.033e+00s\n",
      "2024-02-27 09:17:37,167 - modulus.sym.trainer - INFO - [step:       4000] saved checkpoint to /workspace/10_2D_LDC_Domain_Decomposition/outputs\n",
      "2024-02-27 09:17:37,169 - modulus.sym.trainer - INFO - [step:       4000] loss:  2.646e-04, time/iteration:  1.395e+02 ms\n",
      "2024-02-27 09:17:40,894 - modulus.sym.trainer - INFO - [step:       4100] loss:  4.192e-04, time/iteration:  3.723e+01 ms\n",
      "2024-02-27 09:17:44,605 - modulus.sym.trainer - INFO - [step:       4200] loss:  2.663e-04, time/iteration:  3.709e+01 ms\n",
      "2024-02-27 09:17:48,322 - modulus.sym.trainer - INFO - [step:       4300] loss:  4.233e-04, time/iteration:  3.715e+01 ms\n",
      "2024-02-27 09:17:52,045 - modulus.sym.trainer - INFO - [step:       4400] loss:  3.203e-04, time/iteration:  3.720e+01 ms\n",
      "2024-02-27 09:17:55,796 - modulus.sym.trainer - INFO - [step:       4500] loss:  2.529e-04, time/iteration:  3.748e+01 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 09:17:59,514 - modulus.sym.trainer - INFO - [step:       4600] loss:  4.099e-04, time/iteration:  3.717e+01 ms\n",
      "2024-02-27 09:18:03,234 - modulus.sym.trainer - INFO - [step:       4700] loss:  1.901e-04, time/iteration:  3.718e+01 ms\n",
      "2024-02-27 09:18:06,957 - modulus.sym.trainer - INFO - [step:       4800] loss:  4.157e-04, time/iteration:  3.721e+01 ms\n",
      "2024-02-27 09:18:10,678 - modulus.sym.trainer - INFO - [step:       4900] loss:  4.576e-04, time/iteration:  3.720e+01 ms\n",
      "2024-02-27 09:18:22,256 - modulus.sym.trainer - INFO - [step:       5000] record validators time:  6.978e+00s\n",
      "2024-02-27 09:18:22,342 - modulus.sym.trainer - INFO - [step:       5000] saved checkpoint to /workspace/10_2D_LDC_Domain_Decomposition/outputs\n",
      "2024-02-27 09:18:22,344 - modulus.sym.trainer - INFO - [step:       5000] loss:  3.618e-04, time/iteration:  1.166e+02 ms\n",
      "2024-02-27 09:18:26,093 - modulus.sym.trainer - INFO - [step:       5100] loss:  4.247e-04, time/iteration:  3.748e+01 ms\n",
      "2024-02-27 09:18:29,829 - modulus.sym.trainer - INFO - [step:       5200] loss:  2.562e-04, time/iteration:  3.734e+01 ms\n",
      "2024-02-27 09:18:33,567 - modulus.sym.trainer - INFO - [step:       5300] loss:  2.272e-04, time/iteration:  3.736e+01 ms\n",
      "2024-02-27 09:18:37,304 - modulus.sym.trainer - INFO - [step:       5400] loss:  2.043e-04, time/iteration:  3.736e+01 ms\n",
      "2024-02-27 09:18:41,041 - modulus.sym.trainer - INFO - [step:       5500] loss:  2.378e-04, time/iteration:  3.735e+01 ms\n",
      "2024-02-27 09:18:44,780 - modulus.sym.trainer - INFO - [step:       5600] loss:  1.861e-04, time/iteration:  3.735e+01 ms\n",
      "2024-02-27 09:18:48,549 - modulus.sym.trainer - INFO - [step:       5700] loss:  2.490e-04, time/iteration:  3.767e+01 ms\n",
      "2024-02-27 09:18:52,295 - modulus.sym.trainer - INFO - [step:       5800] loss:  2.408e-04, time/iteration:  3.744e+01 ms\n",
      "2024-02-27 09:18:56,035 - modulus.sym.trainer - INFO - [step:       5900] loss:  2.224e-04, time/iteration:  3.738e+01 ms\n",
      "2024-02-27 09:19:00,772 - modulus.sym.trainer - INFO - [step:       6000] record constraint batch time:  1.359e-01s\n",
      "2024-02-27 09:19:07,781 - modulus.sym.trainer - INFO - [step:       6000] record validators time:  7.006e+00s\n",
      "2024-02-27 09:19:09,869 - modulus.sym.trainer - INFO - [step:       6000] record inferencers time:  2.072e+00s\n",
      "2024-02-27 09:19:09,941 - modulus.sym.trainer - INFO - [step:       6000] saved checkpoint to /workspace/10_2D_LDC_Domain_Decomposition/outputs\n",
      "2024-02-27 09:19:09,943 - modulus.sym.trainer - INFO - [step:       6000] loss:  3.037e-04, time/iteration:  1.391e+02 ms\n",
      "2024-02-27 09:19:13,673 - modulus.sym.trainer - INFO - [step:       6100] loss:  2.938e-04, time/iteration:  3.729e+01 ms\n",
      "2024-02-27 09:19:17,392 - modulus.sym.trainer - INFO - [step:       6200] loss:  2.704e-04, time/iteration:  3.717e+01 ms\n",
      "2024-02-27 09:19:21,115 - modulus.sym.trainer - INFO - [step:       6300] loss:  3.517e-04, time/iteration:  3.721e+01 ms\n",
      "2024-02-27 09:19:24,840 - modulus.sym.trainer - INFO - [step:       6400] loss:  2.979e-04, time/iteration:  3.723e+01 ms\n",
      "2024-02-27 09:19:28,566 - modulus.sym.trainer - INFO - [step:       6500] loss:  1.742e-04, time/iteration:  3.724e+01 ms\n",
      "2024-02-27 09:19:32,290 - modulus.sym.trainer - INFO - [step:       6600] loss:  2.566e-04, time/iteration:  3.721e+01 ms\n",
      "2024-02-27 09:19:36,018 - modulus.sym.trainer - INFO - [step:       6700] loss:  2.201e-04, time/iteration:  3.726e+01 ms\n",
      "2024-02-27 09:19:39,745 - modulus.sym.trainer - INFO - [step:       6800] loss:  2.102e-04, time/iteration:  3.724e+01 ms\n",
      "2024-02-27 09:19:43,471 - modulus.sym.trainer - INFO - [step:       6900] loss:  1.688e-04, time/iteration:  3.724e+01 ms\n",
      "2024-02-27 09:19:54,938 - modulus.sym.trainer - INFO - [step:       7000] record validators time:  6.925e+00s\n",
      "2024-02-27 09:19:55,025 - modulus.sym.trainer - INFO - [step:       7000] saved checkpoint to /workspace/10_2D_LDC_Domain_Decomposition/outputs\n",
      "2024-02-27 09:19:55,027 - modulus.sym.trainer - INFO - [step:       7000] loss:  1.864e-04, time/iteration:  1.155e+02 ms\n",
      "2024-02-27 09:19:58,779 - modulus.sym.trainer - INFO - [step:       7100] loss:  3.896e-04, time/iteration:  3.751e+01 ms\n",
      "2024-02-27 09:20:02,507 - modulus.sym.trainer - INFO - [step:       7200] loss:  2.140e-04, time/iteration:  3.726e+01 ms\n",
      "2024-02-27 09:20:06,228 - modulus.sym.trainer - INFO - [step:       7300] loss:  1.634e-04, time/iteration:  3.719e+01 ms\n",
      "2024-02-27 09:20:09,948 - modulus.sym.trainer - INFO - [step:       7400] loss:  2.248e-04, time/iteration:  3.718e+01 ms\n",
      "2024-02-27 09:20:13,668 - modulus.sym.trainer - INFO - [step:       7500] loss:  2.473e-04, time/iteration:  3.717e+01 ms\n",
      "2024-02-27 09:20:17,396 - modulus.sym.trainer - INFO - [step:       7600] loss:  2.711e-04, time/iteration:  3.726e+01 ms\n",
      "2024-02-27 09:20:21,122 - modulus.sym.trainer - INFO - [step:       7700] loss:  1.756e-04, time/iteration:  3.724e+01 ms\n",
      "2024-02-27 09:20:24,847 - modulus.sym.trainer - INFO - [step:       7800] loss:  2.371e-04, time/iteration:  3.723e+01 ms\n",
      "2024-02-27 09:20:28,571 - modulus.sym.trainer - INFO - [step:       7900] loss:  1.209e-04, time/iteration:  3.722e+01 ms\n",
      "2024-02-27 09:20:33,262 - modulus.sym.trainer - INFO - [step:       8000] record constraint batch time:  1.350e-01s\n",
      "2024-02-27 09:20:40,480 - modulus.sym.trainer - INFO - [step:       8000] record validators time:  7.216e+00s\n",
      "2024-02-27 09:20:42,565 - modulus.sym.trainer - INFO - [step:       8000] record inferencers time:  2.065e+00s\n",
      "2024-02-27 09:20:42,637 - modulus.sym.trainer - INFO - [step:       8000] saved checkpoint to /workspace/10_2D_LDC_Domain_Decomposition/outputs\n",
      "2024-02-27 09:20:42,640 - modulus.sym.trainer - INFO - [step:       8000] loss:  2.463e-04, time/iteration:  1.407e+02 ms\n",
      "2024-02-27 09:20:46,356 - modulus.sym.trainer - INFO - [step:       8100] loss:  3.607e-04, time/iteration:  3.715e+01 ms\n",
      "2024-02-27 09:20:50,060 - modulus.sym.trainer - INFO - [step:       8200] loss:  2.067e-04, time/iteration:  3.702e+01 ms\n",
      "2024-02-27 09:20:53,769 - modulus.sym.trainer - INFO - [step:       8300] loss:  2.028e-04, time/iteration:  3.708e+01 ms\n",
      "2024-02-27 09:20:57,479 - modulus.sym.trainer - INFO - [step:       8400] loss:  5.829e-04, time/iteration:  3.708e+01 ms\n",
      "2024-02-27 09:21:01,190 - modulus.sym.trainer - INFO - [step:       8500] loss:  1.493e-04, time/iteration:  3.709e+01 ms\n",
      "2024-02-27 09:21:04,898 - modulus.sym.trainer - INFO - [step:       8600] loss:  1.730e-04, time/iteration:  3.704e+01 ms\n",
      "2024-02-27 09:21:08,613 - modulus.sym.trainer - INFO - [step:       8700] loss:  2.404e-04, time/iteration:  3.713e+01 ms\n",
      "2024-02-27 09:21:12,349 - modulus.sym.trainer - INFO - [step:       8800] loss:  2.197e-04, time/iteration:  3.734e+01 ms\n",
      "2024-02-27 09:21:16,069 - modulus.sym.trainer - INFO - [step:       8900] loss:  2.015e-04, time/iteration:  3.719e+01 ms\n",
      "2024-02-27 09:21:27,463 - modulus.sym.trainer - INFO - [step:       9000] record validators time:  6.886e+00s\n",
      "2024-02-27 09:21:27,548 - modulus.sym.trainer - INFO - [step:       9000] saved checkpoint to /workspace/10_2D_LDC_Domain_Decomposition/outputs\n",
      "2024-02-27 09:21:27,550 - modulus.sym.trainer - INFO - [step:       9000] loss:  3.195e-04, time/iteration:  1.148e+02 ms\n",
      "2024-02-27 09:21:31,285 - modulus.sym.trainer - INFO - [step:       9100] loss:  1.293e-04, time/iteration:  3.734e+01 ms\n",
      "2024-02-27 09:21:35,013 - modulus.sym.trainer - INFO - [step:       9200] loss:  3.633e-04, time/iteration:  3.726e+01 ms\n",
      "2024-02-27 09:21:38,747 - modulus.sym.trainer - INFO - [step:       9300] loss:  2.051e-04, time/iteration:  3.731e+01 ms\n",
      "2024-02-27 09:21:42,477 - modulus.sym.trainer - INFO - [step:       9400] loss:  1.912e-04, time/iteration:  3.728e+01 ms\n",
      "2024-02-27 09:21:46,211 - modulus.sym.trainer - INFO - [step:       9500] loss:  2.562e-04, time/iteration:  3.732e+01 ms\n",
      "2024-02-27 09:21:49,946 - modulus.sym.trainer - INFO - [step:       9600] loss:  2.128e-04, time/iteration:  3.734e+01 ms\n",
      "2024-02-27 09:21:53,680 - modulus.sym.trainer - INFO - [step:       9700] loss:  3.411e-04, time/iteration:  3.732e+01 ms\n",
      "2024-02-27 09:21:57,415 - modulus.sym.trainer - INFO - [step:       9800] loss:  2.045e-04, time/iteration:  3.733e+01 ms\n",
      "2024-02-27 09:22:01,148 - modulus.sym.trainer - INFO - [step:       9900] loss:  1.537e-04, time/iteration:  3.731e+01 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-27 09:22:05,831 - modulus.sym.trainer - INFO - [step:      10000] record constraint batch time:  1.360e-01s\n",
      "2024-02-27 09:22:12,728 - modulus.sym.trainer - INFO - [step:      10000] record validators time:  6.895e+00s\n",
      "2024-02-27 09:22:14,828 - modulus.sym.trainer - INFO - [step:      10000] record inferencers time:  2.072e+00s\n",
      "2024-02-27 09:22:14,896 - modulus.sym.trainer - INFO - [step:      10000] saved checkpoint to /workspace/10_2D_LDC_Domain_Decomposition/outputs\n",
      "2024-02-27 09:22:14,898 - modulus.sym.trainer - INFO - [step:      10000] loss:  2.449e-04, time/iteration:  1.375e+02 ms\n",
      "2024-02-27 09:22:14,900 - modulus.sym.trainer - INFO - [step:      10000] reached maximum training steps, finished training!\n"
     ]
    }
   ],
   "source": [
    "slv.solve()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556674b9",
   "metadata": {},
   "source": [
    "### 后处理以及可视化\n",
    "\n",
    "对于jupyter，比较方便的方法是使用matplotlib\n",
    "\n",
    "此外，还可以使用tensorboard以及Paraview\n",
    "\n",
    "如果使用了PointwiseValidator则可以直接查看验证的结果：\n",
    "\n",
    "![u](./outputs/validators/validator_u.png)\n",
    "![v](./outputs/validators/validator_v.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848c2826",
   "metadata": {},
   "source": [
    "非常显著的界面过度不平滑"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
